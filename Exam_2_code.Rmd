---
title: "7393 Exam 2 R Code Andrei Matveev"
output: html_notebook
---
```{r Data and set up}

library(data.table)
library(truncnorm)
library(coda)
library(rstan) 
library(shinystan)
library(invgamma)

library(bayesplot)
install.packages("posterior", repos = c("https://mc-stan.org/r-packages/", getOption("repos")))
library("posterior")
devtools::install_github("stan-dev/loo")


devtools::install_github("jfrench/bayesutils")
setwd('/Users/AM/Documents/_CU Masters/2020 fall Bayesian_7393/code/Bayesian_Statistics_Class_Code/Exam_code')
#df1 = load("diamonds_simple.rda")
#rm(df1, diamonds_simple)
df = bayesutils::diamonds_simple

df$lprice = log(df$price)
df$lcarat = log(df$carat)

```

```{r Problem 1 log density Function}

lq_theta_y = function(sigmaSQ, beta0, beta1, lpr = df$lprice, lcar = df$lcarat) {
  ld = dnorm(beta0, 0, 100, log = TRUE) + 
    dnorm(beta1, 0, 100, log = TRUE) + 
    dinvgamma(sigmaSQ, shape = 0.01, rate = 0.01, log = TRUE) +
    sum(dnorm(lpr, mean = (beta0 + beta1 * lcar), sd = sqrt(sigmaSQ), log = TRUE))
  return(ld)
}

```

```{r Problem 1 mh Function}

mh = function(B, theta_start) {
  theta = array(0, c((B+1), 3), dimnames = list(c(), c("sigmaSQ", "beta0", "beta1")))
  
  theta[1,1] = theta_start[1]
  theta[1,2] = theta_start[2]
  theta[1,3] = theta_start[3]

  for (i in 2:dim(theta)[1]) {
    
    ###  step for sigmaSQ
    beta0_star = theta[(i-1),2]
    beta1_star = theta[(i-1),3]
    
    sigmaSQ_star = rtruncnorm(n = 1, a=0, b=Inf, mean = theta[(i-1),1], sd = 0.1)

    num_logr = lq_theta_y(sigmaSQ = sigmaSQ_star, beta0 = beta0_star, beta1 = beta1_star) -
      log(dtruncnorm(x = sigmaSQ_star, a=0, b=Inf, mean = theta[(i-1),1], sd = 0.1))
    den_logr = lq_theta_y(sigmaSQ = theta[i-1, 1], beta0 = beta0_star, beta1 = beta1_star) -
      log(dtruncnorm(x = theta[i-1, 1], a=0, b=Inf, mean = sigmaSQ_star, sd = 0.1)) 
## !!! is the mean correct? Should  we use in den_logr mean = sigmaSQ_star or mean = theta[i-1, 1]? 
# check c-componentwise-mh v1 line 68, 72
    logr = num_logr - den_logr
    if (log(runif(1)) <= min(logr, 0)) {
      theta[i,1] = sigmaSQ_star
    } else {
      theta[i,1] = theta[(i - 1), 1]
    }
    
    ###  step for beta0
    beta1_star = theta[(i-1),3] # it is the repeated code, but I need it to keep the interpretability
    sigmaSQ_star = theta[i,1] # update sigmaSQ_star after the Gibbs step for sigmaSQ
    
    beta0_star = rnorm(1, theta[(i-1),2], 0.1) # !!! check the parametrization (0.1 or 0.1^2)
    
    num_logr = lq_theta_y(sigmaSQ = sigmaSQ_star, beta0 = beta0_star, beta1 = beta1_star) -
      dnorm(x = beta0_star, mean = theta[(i-1),2], sd = 0.1, log = TRUE)
    den_logr = lq_theta_y(sigmaSQ = sigmaSQ_star, beta0 = theta[i-1, 2], beta1 = beta1_star) -
      dnorm(x = theta[(i-1),2], mean = beta0_star, sd = 0.1, log = TRUE)
## !!! is the mean correct? Should  we use in den_logr mean = sigmaSQ_star or mean = theta[i-1, 1]? 
# check c-componentwise-mh v1 line 68, 72
    logr = num_logr - den_logr
    if (log(runif(1)) <= min(logr, 0)) {
      theta[i,2] = beta0_star
    } else {
      theta[i,2] = theta[(i - 1), 2]
    }
    
    ###  step for beta1
    sigmaSQ_star = theta[i,1] # it is the repeated code, but I need it to keep the interpretability
    beta0_star = theta[i,2] # update beta0_star after the Gibbs step for beta0

    beta1_star = rnorm(1, theta[(i-1),3], 0.1) # !!! check the parametrization (0.1 or 0.1^2)
    
    num_logr = lq_theta_y(sigmaSQ = sigmaSQ_star, beta0 = beta0_star, beta1 = beta1_star) -
      dnorm(x = beta1_star, mean = theta[(i-1),3], sd = 0.1, log = TRUE)
    den_logr = lq_theta_y(sigmaSQ = sigmaSQ_star, beta0 = beta0_star, beta1 = theta[i-1, 3]) -
      dnorm(x = theta[(i-1),3], mean = beta1_star, sd = 0.1, log = TRUE)
## !!! is the mean correct? Should  we use in den_logr mean = sigmaSQ_star or mean = theta[i-1, 1]? 
# check c-componentwise-mh v1 line 68, 72
    logr = num_logr - den_logr
    if (log(runif(1)) <= min(logr, 0)) {
      theta[i,3] = beta1_star
    } else {
      theta[i,3] = theta[(i - 1), 3]
    }
    
  }
  return(theta)
}

```

```{r Problem 1 mh Run}

B = 10^5 
keep = (B/2 + 1):(B + 1)
chain1 = mh(B, theta_start = c(0.1, -1, -1))
chain2 = mh(B, theta_start = c(0.3, 0, 0))
chain3 = mh(B, theta_start = c(0.5, -1, 1))
chain4 = mh(B, theta_start = c(0.2, 1, 1))

mc = mcmc.list(mcmc(chain1[keep,]), mcmc(chain2[keep,]),
                 mcmc(chain3[keep,]), mcmc(chain4[keep,]))
summary(mc)

```

```{r Problem 2 to assess the convergence}

keep = (B/2 + 19001):(B/2 + 20001)

mc = mcmc.list(mcmc(chain1[keep,]), mcmc(chain2[keep,]),
                 mcmc(chain3[keep,]), mcmc(chain4[keep,]))
coda::traceplot(mc)
coda::autocorr.plot(mc, lag.max = 100, auto.layout = TRUE)
gelman.diag(mc, autoburnin = FALSE)
geweke.diag(mc)

```

```{r Problem 3 Model A, include=FALSE}
stan_mod_A = "
data {
  int T;
  vector[T] lpr;    // log price 
  vector[T] lcar;   // log carat 
  real<lower=0> v;  // sample variance of log price 

}

parameters {
  real<lower=0> sigmaSQ;
  real beta0;
  real beta1;
}

transformed parameters {
  vector[T] mu;
  for (i in 1:T) {
    mu[i] = beta0 + beta1 * lcar[i];
  }

}

model {
  sigmaSQ ~ inv_gamma(0.01, 0.01);
  beta0 ~ normal(0, 100);
  beta1 ~ normal(0, 100);

  for (i in 1:T)
    lpr[i] ~ normal(mu[i], sqrt(sigmaSQ));
}
generated quantities {
  vector[T] log_lik;
  vector[T] y_rep;

  //vector[T] lik;
  real Rbsq;              // goodness-of-fit
  Rbsq = 1 - sigmaSQ/v;
  
  for (i in 1:T) {
    log_lik[i] = normal_lpdf(lpr[i] | mu[i], sqrt(sigmaSQ));
    y_rep[i] = normal_rng(mu[i], sqrt(sigmaSQ));
    //lik[i] = exp(log_lik[i]);
  }

}
"

T <- length(df$lprice)
v = var(df$lprice)
set.seed(90)

model_name = "Model_A_"
stan_dat_A = list(T = T, lpr = df$lprice, lcar = df$lcarat, v = v)
r_fit_A = stan(model_code = stan_mod_A, data = stan_dat_A, 
             iter = 5000, chains = 4, 
             control = list(max_treedepth = 21))

#file_name = paste(model_name, as.character(Sys.Date()), ".rda", sep="")
#setwd('/Users/AM/Documents/_CU Masters/2020 fall Bayesian_7393/code/Bayesian_Statistics_Class_Code/Exam_code')
#readRDS(r_fit, file = "") 
#saveRDS(r_fit, file = file_name, compress = "xz") 

summary(r_fit_A, pars = c("sigmaSQ", "beta0", "beta1"), prob = c(0.025, 0.975))$summary

#sso <- launch_shinystan(r_fit_A)

```

```{r Problem 3 Model B, include=FALSE}
stan_mod_B = "
data {
  int T;
  vector[T] lpr;    // log price 
  vector[T] lcar;   // log carat 
  real<lower=0> v;  // sample variance of log price 

}

parameters {
  real<lower=0> sigmaSQ;
  real beta0;
  real beta1;
  real beta2;
}

transformed parameters {
  vector[T] mu;
  for (i in 1:T) {
    mu[i] = beta0 + beta1 * lcar[i] + beta2 * lcar[i] * lcar[i];
  }

}

model {
  sigmaSQ ~ inv_gamma(0.01, 0.01);
  beta0 ~ normal(0, 100);
  beta1 ~ normal(0, 100);
  beta2 ~ normal(0, 100);

  for (i in 1:T)
    lpr[i] ~ normal(mu[i], sqrt(sigmaSQ));
}

generated quantities {
  vector[T] y_rep;
  vector[T] log_lik;
  //vector[T] lik;
  real Rbsq;              // goodness-of-fit
  Rbsq = 1 - sigmaSQ/v;
  
  for (i in 1:T) {
    log_lik[i] = normal_lpdf(lpr[i] | mu[i], sqrt(sigmaSQ));
    y_rep[i] = normal_rng(mu[i], sqrt(sigmaSQ));

    //lik[i] = exp(log_lik[i]);
  }

}
"

T <- length(df$lprice)
v = var(df$lprice)
set.seed(91)

model_name = "Model_B_"
stan_dat_B = list(T = T, lpr = df$lprice, lcar = df$lcarat, v = v)
r_fit_B = stan(model_code = stan_mod_B, data = stan_dat_B, 
             iter = 5000, chains = 4, 
             control = list(max_treedepth = 21))

#file_name = paste(model_name, as.character(Sys.time()), ".rda", sep="")
#setwd('/Users/AM/Documents/_CU Masters/2020 fall Bayesian_7393/code/Bayesian_Statistics_Class_Code/Exam_code')
#saveRDS(r_fit, file = file_name, compress = "xz") 
summary(r_fit_B, pars = c("sigmaSQ", "beta0", "beta1", "beta2"), prob = c(0.025, 0.975))$summary

sso <- launch_shinystan(r_fit_B)

```

```{r Problem 4 Model A}
posterior <- as.matrix(r_fit_A)

posterior <- as.array(r_fit_A)

yrep <- posterior_predict(r_fit_A, draws = 10)

yrep <- posterior_predict(example_model)

color_scheme_set("red")
ppc_dens_overlay(y = r_fit_A$,
                 yrep = posterior_predict(r_fit_A, draws = 50))

pp_check(r_fit_A)
pp_check(r_fit_A, fun = "hist")

```

```{r Problem 5 Model C, include=FALSE}
stan_mod_C = "
data {
  int T;
  vector[T] pr;    //  price 
  vector[T] lcar;   // log carat 
  real<lower=0> v;  // sample variance of log price 

}

parameters {
  real<lower=0> sigmaSQ;
  real beta0;
  real beta1;
}

transformed parameters {
  vector[T] mu;
  for (i in 1:T) {
    mu[i] = beta0 + beta1 * lcar[i];
  }

}

model {
  sigmaSQ ~ inv_gamma(0.01, 0.01);
  beta0 ~ normal(0, 100);
  beta1 ~ normal(0, 100);

  for (i in 1:T)
    pr[i] ~ lognormal(mu[i], sqrt(sigmaSQ));
}
generated quantities {
  vector[T] log_lik;
  vector[T] y_rep;

  //vector[T] lik;
  real Rbsq;              // goodness-of-fit
  Rbsq = 1 - sigmaSQ/v;
  
  for (i in 1:T) {
    log_lik[i] = lognormal_lpdf(pr[i] | mu[i], sqrt(sigmaSQ));
    y_rep[i] = lognormal_rng(mu[i], sqrt(sigmaSQ));
    //lik[i] = exp(log_lik[i]);
  }

}
"

T <- length(df$price)
v = var(df$price)
set.seed(92)

model_name = "Model_C_"
stan_dat_C = list(T = T, pr = df$price, lcar = df$lcarat, v = v)
r_fit_C = stan(model_code = stan_mod_C, data = stan_dat_C, 
             iter = 5000, chains = 4, 
             control = list(max_treedepth = 21))

#file_name = paste(model_name, as.character(Sys.Date()), ".rda", sep="")
#setwd('/Users/AM/Documents/_CU Masters/2020 fall Bayesian_7393/code/Bayesian_Statistics_Class_Code/Exam_code')
#readRDS(r_fit, file = "") 
#saveRDS(r_fit, file = file_name, compress = "xz") 

summary(r_fit_C, pars = c("sigmaSQ", "beta0", "beta1"), prob = c(0.025, 0.975))$summary

#sso <- launch_shinystan(r_fit_A)

```
